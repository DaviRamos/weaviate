name: Projetoweaviate

networks:
  local-network:
    external: true

volumes:
  ollama-data:
  weaviate_data:

services:
  weaviate:
    command: ["--host", "0.0.0.0", "--port", "8080","--scheme", "http"]  
    image: cr.weaviate.io/semitechnologies/weaviate:1.30.0
    networks:
      - local-network
    ports:
    - 8080:8080
    - 50051:50051
    volumes:
    - weaviate_data:/var/lib/weaviate
    restart: on-failure:0
    environment:
      NER_INFERENCE_API: 'http://ner-transformers:8080'
      SUM_INFERENCE_API: 'http://sum-transformers:8080'
      RERANKER_INFERENCE_API: 'http://reranker-transformers:8080'
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      #ENABLE_API_BASED_MODULES: 'true'
      DEFAULT_VECTORIZER_MODULE: 'text2vec-ollama'
      ENABLE_MODULES: 'text2vec-ollama,ner-transformers,sum-transformers,generative-ollama,reranker-transformers'
      CLUSTER_HOSTNAME: 'node1'
  ner-transformers:
    image: cr.weaviate.io/semitechnologies/ner-transformers:dbmdz-bert-large-cased-finetuned-conll03-english
    networks:
      - local-network
    environment:
      ENABLE_CUDA: '0'
  sum-transformers:
    image: cr.weaviate.io/semitechnologies/sum-transformers:facebook-bart-large-cnn-1.0.0
    networks:
      - local-network
    environment:
      ENABLE_CUDA: '0'
  ollama:
    image: ollama/ollama
    container_name: ollama-container
    networks:
      - local-network
    volumes:
      - ollama-data:/root/.ollama
    command: ["ollama", "pull", "llama3.2", "nomic-embed-text"]
    ports:
      - "11434:11434"
    pull_policy: always
    tty: true
    restart: always
    deploy:
      resources:
        limits:
          cpus: '0.50'
          memory: 256M
        reservations:
          cpus: '0.25'  
          devices:
            - driver: ${OLLAMA_GPU_DRIVER-nvidia}
              count: ${OLLAMA_GPU_COUNT-1}
              capabilities:
                - gpu  
  reranker-transformers:
    image: cr.weaviate.io/semitechnologies/reranker-transformers:cross-encoder-ms-marco-MiniLM-L-6-v2
    networks:
      - local-network
    environment:
      ENABLE_CUDA: '0'      